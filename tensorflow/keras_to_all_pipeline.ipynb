{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x7f2c6761a4a8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.applications.ResNet50()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = Path('./models/'); MODELS.ls()\n",
    "\n",
    "def inputs_same(x1,x2): return np.all(np.isclose(x1, x2, atol=1e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get input ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = open_image(\"cat224x224.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_img = normalize(img.data, tensor(imagenet_stats[0]), tensor(imagenet_stats[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch x width x height x channel\n",
    "torch_input = normalized_img.data[None, ...].permute(0,3,2,1)\n",
    "numpy_input = to_np(torch_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_name = 'vgg16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n02124075', 'Egyptian_cat', 0.30435446), ('n02123045', 'tabby', 0.2010841), ('n02123159', 'tiger_cat', 0.15228517)]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "keras_model = VGG16(weights='imagenet')\n",
    "\n",
    "img_path = 'cat224x224.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "numpy_input = preprocess_input(x)\n",
    "\n",
    "keras_output = keras_model.predict(numpy_input)\n",
    "print('Predicted:', decode_predictions(keras_output, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.save(MODELS/f'{arch_name}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras to TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = tf.graph_util.convert_variables_to_constants(\n",
    "            session, input_graph_def, output_names, freeze_var_names)\n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model.training=False\n",
    "tf.keras.backend.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.keras.backend.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get graph definition\n",
    "gd = sess.graph.as_graph_def()\n",
    "\n",
    "# # fix batch norm nodes\n",
    "# for node in graph_def.node:\n",
    "#     if (node.op == 'RefSwitch') or (node.op == 'Switch'):\n",
    "#         node.op = 'Switch'\n",
    "#         for index in range(len(node.input)):\n",
    "#             if 'moving_' in node.input[index]:\n",
    "#                 node.input[index] = node.input[index] + '/read'\n",
    "#     elif node.op == 'AssignSub':\n",
    "#         node.op = 'Sub'\n",
    "#         if 'use_locking' in node.attr: del node.attr['use_locking']\n",
    "#     elif node.op == 'AssignAdd':\n",
    "#         node.op = 'Add'\n",
    "#         if 'use_locking' in node.attr: del node.attr['use_locking']\n",
    "#     elif node.op == 'Assign':\n",
    "#         node.op = 'Identity'\n",
    "#         if 'use_locking' in node.attr: del node.attr['use_locking']\n",
    "#         if 'validate_shape' in node.attr: del node.attr['validate_shape']\n",
    "#         if len(node.input) == 2:\n",
    "#             # input0: ref: Should be from a Variable node. May be uninitialized.\n",
    "#             # input1: value: The value to be assigned to the variable.\n",
    "#             node.input[0] = node.input[1]\n",
    "#             del node.input[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import graph_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'predictions/Softmax:0' shape=(?, 1000) dtype=float32>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'predictions/Softmax'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model.output.name.split(':')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 32 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 32 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted 32 variables to const ops.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted 32 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/vgg16.pb'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate protobuf\n",
    "converted_graph_def = graph_util.convert_variables_to_constants(sess, gd, ['predictions/Softmax'])\n",
    "tf.train.write_graph(converted_graph_def, str(MODELS), f'{arch_name}.pb', as_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Keras and TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2onnx\n",
    "from tensorflow.python.framework import graph_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_def = tf.GraphDef()\n",
    "with tf.gfile.GFile(str(MODELS/f'{arch_name}.pb'), \"rb\") as f:\n",
    "    graph_def.ParseFromString(f.read())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default() as graph:\n",
    "    tf.import_graph_def(graph_def, name=\"prefix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as sess:   \n",
    "    input_node = graph.get_tensor_by_name(\"prefix/\"+keras_model.input.name)\n",
    "    output_node = graph.get_tensor_by_name(\"prefix/\"+keras_model.output.name)\n",
    "    feed_dict={input_node: numpy_input}\n",
    "    tf_output = sess.run(output_node, feed_dict)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras with TF\n",
    "if not inputs_same(keras_output[0], tf_output[0]):\n",
    "    raise Exception(\"Keras and TF outputs are not same\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF to CoreML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:TensorFlow version 1.13.1 detected. Last version known to be fully compatible is 1.12.0 .\n"
     ]
    }
   ],
   "source": [
    "import tfcoreml as tf_converter\n",
    "import onnxmltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prefix/input_2:0'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"prefix/\"+keras_model.input.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'prefix/predictions/Softmax:0' shape=(?, 1000) dtype=float32>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_tensor_by_name(\"prefix/\"+keras_model.output.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the TF graph...\n",
      "Graph Loaded.\n",
      "Collecting all the 'Const' ops from the graph, by running it....\n",
      "Done.\n",
      "Now finding ops in the TF graph that can be dropped for inference\n",
      "Now starting translation to CoreML graph.\n",
      "Automatic shape interpretation succeeded for input blob input_2:0\n",
      "1/126: Analysing op name: predictions/bias ( type:  Const )\n",
      "2/126: Analysing op name: predictions/BiasAdd/ReadVariableOp ( type:  Identity )\n",
      "3/126: Analysing op name: predictions/kernel ( type:  Const )\n",
      "4/126: Analysing op name: predictions/MatMul/ReadVariableOp ( type:  Identity )\n",
      "5/126: Analysing op name: fc2/bias ( type:  Const )\n",
      "6/126: Analysing op name: fc2/BiasAdd/ReadVariableOp ( type:  Identity )\n",
      "7/126: Analysing op name: fc2/kernel ( type:  Const )\n",
      "8/126: Analysing op name: fc2/MatMul/ReadVariableOp ( type:  Identity )\n",
      "9/126: Analysing op name: fc1/bias ( type:  Const )\n",
      "10/126: Analysing op name: fc1/BiasAdd/ReadVariableOp ( type:  Identity )\n",
      "11/126: Analysing op name: fc1/kernel ( type:  Const )\n",
      "12/126: Analysing op name: fc1/MatMul/ReadVariableOp ( type:  Identity )\n",
      "13/126: Analysing op name: flatten/Reshape/shape/1 ( type:  Const )\n",
      "14/126: Analysing op name: flatten/strided_slice/stack_2 ( type:  Const )\n",
      "15/126: Analysing op name: flatten/strided_slice/stack_1 ( type:  Const )\n",
      "16/126: Analysing op name: flatten/strided_slice/stack ( type:  Const )\n",
      "17/126: Analysing op name: block5_conv3/bias ( type:  Const )\n",
      "18/126: Analysing op name: block5_conv3/BiasAdd/ReadVariableOp ( type:  Identity )\n",
      "19/126: Analysing op name: block5_conv3/kernel ( type:  Const )\n",
      "20/126: Analysing op name: block5_conv3/Conv2D/ReadVariableOp ( type:  Identity )\n",
      "21/126: Analysing op name: block5_conv2/bias ( type:  Const )\n",
      "22/126: Analysing op name: block5_conv2/BiasAdd/ReadVariableOp ( type:  Identity )\n",
      "23/126: Analysing op name: block5_conv2/kernel ( type:  Const )\n",
      "24/126: Analysing op name: block5_conv2/Conv2D/ReadVariableOp ( type:  Identity )\n",
      "25/126: Analysing op name: block5_conv1/bias ( type:  Const )\n",
      "26/126: Analysing op name: block5_conv1/BiasAdd/ReadVariableOp ( type:  Identity )\n",
      "27/126: Analysing op name: block5_conv1/kernel ( type:  Const )\n",
      "28/126: Analysing op name: block5_conv1/Conv2D/ReadVariableOp ( type:  Identity )\n",
      "29/126: Analysing op name: block4_conv3/bias ( type:  Const )\n",
      "30/126: Analysing op name: block4_conv3/BiasAdd/ReadVariableOp ( type:  Identity )\n",
      "31/126: Analysing op name: block4_conv3/kernel ( type:  Const )\n",
      "32/126: Analysing op name: block4_conv3/Conv2D/ReadVariableOp ( type:  Identity )\n",
      "33/126: Analysing op name: block4_conv2/bias ( type:  Const )\n",
      "34/126: Analysing op name: block4_conv2/BiasAdd/ReadVariableOp ( type:  Identity )\n",
      "35/126: Analysing op name: block4_conv2/kernel ( type:  Const )\n",
      "36/126: Analysing op name: block4_conv2/Conv2D/ReadVariableOp ( type:  Identity )\n",
      "37/126: Analysing op name: block4_conv1/bias ( type:  Const )\n",
      "38/126: Analysing op name: block4_conv1/BiasAdd/ReadVariableOp ( type:  Identity )\n",
      "39/126: Analysing op name: block4_conv1/kernel ( type:  Const )\n",
      "40/126: Analysing op name: block4_conv1/Conv2D/ReadVariableOp ( type:  Identity )\n",
      "41/126: Analysing op name: block3_conv3/bias ( type:  Const )\n",
      "42/126: Analysing op name: block3_conv3/BiasAdd/ReadVariableOp ( type:  Identity )\n",
      "43/126: Analysing op name: block3_conv3/kernel ( type:  Const )\n",
      "44/126: Analysing op name: block3_conv3/Conv2D/ReadVariableOp ( type:  Identity )\n",
      "45/126: Analysing op name: block3_conv2/bias ( type:  Const )\n",
      "46/126: Analysing op name: block3_conv2/BiasAdd/ReadVariableOp ( type:  Identity )\n",
      "47/126: Analysing op name: block3_conv2/kernel ( type:  Const )\n",
      "48/126: Analysing op name: block3_conv2/Conv2D/ReadVariableOp ( type:  Identity )\n",
      "49/126: Analysing op name: block3_conv1/bias ( type:  Const )\n",
      "50/126: Analysing op name: block3_conv1/BiasAdd/ReadVariableOp ( type:  Identity )\n",
      "51/126: Analysing op name: block3_conv1/kernel ( type:  Const )\n",
      "52/126: Analysing op name: block3_conv1/Conv2D/ReadVariableOp ( type:  Identity )\n",
      "53/126: Analysing op name: block2_conv2/bias ( type:  Const )\n",
      "54/126: Analysing op name: block2_conv2/BiasAdd/ReadVariableOp ( type:  Identity )\n",
      "55/126: Analysing op name: block2_conv2/kernel ( type:  Const )\n",
      "56/126: Analysing op name: block2_conv2/Conv2D/ReadVariableOp ( type:  Identity )\n",
      "57/126: Analysing op name: block2_conv1/bias ( type:  Const )\n",
      "58/126: Analysing op name: block2_conv1/BiasAdd/ReadVariableOp ( type:  Identity )\n",
      "59/126: Analysing op name: block2_conv1/kernel ( type:  Const )\n",
      "60/126: Analysing op name: block2_conv1/Conv2D/ReadVariableOp ( type:  Identity )\n",
      "61/126: Analysing op name: block1_conv2/bias ( type:  Const )\n",
      "62/126: Analysing op name: block1_conv2/BiasAdd/ReadVariableOp ( type:  Identity )\n",
      "63/126: Analysing op name: block1_conv2/kernel ( type:  Const )\n",
      "64/126: Analysing op name: block1_conv2/Conv2D/ReadVariableOp ( type:  Identity )\n",
      "65/126: Analysing op name: block1_conv1/bias ( type:  Const )\n",
      "66/126: Analysing op name: block1_conv1/BiasAdd/ReadVariableOp ( type:  Identity )\n",
      "67/126: Analysing op name: block1_conv1/kernel ( type:  Const )\n",
      "68/126: Analysing op name: block1_conv1/Conv2D/ReadVariableOp ( type:  Identity )\n",
      "69/126: Analysing op name: input_2 ( type:  Placeholder )\n",
      "Skipping name of placeholder\n",
      "70/126: Analysing op name: block1_conv1/Conv2D ( type:  Conv2D )\n",
      "71/126: Analysing op name: block1_conv1/BiasAdd ( type:  BiasAdd )\n",
      "72/126: Analysing op name: block1_conv1/Relu ( type:  Relu )\n",
      "73/126: Analysing op name: block1_conv2/Conv2D ( type:  Conv2D )\n",
      "74/126: Analysing op name: block1_conv2/BiasAdd ( type:  BiasAdd )\n",
      "75/126: Analysing op name: block1_conv2/Relu ( type:  Relu )\n",
      "76/126: Analysing op name: block1_pool/MaxPool ( type:  MaxPool )\n",
      "77/126: Analysing op name: block2_conv1/Conv2D ( type:  Conv2D )\n",
      "78/126: Analysing op name: block2_conv1/BiasAdd ( type:  BiasAdd )\n",
      "79/126: Analysing op name: block2_conv1/Relu ( type:  Relu )\n",
      "80/126: Analysing op name: block2_conv2/Conv2D ( type:  Conv2D )\n",
      "81/126: Analysing op name: block2_conv2/BiasAdd ( type:  BiasAdd )\n",
      "82/126: Analysing op name: block2_conv2/Relu ( type:  Relu )\n",
      "83/126: Analysing op name: block2_pool/MaxPool ( type:  MaxPool )\n",
      "84/126: Analysing op name: block3_conv1/Conv2D ( type:  Conv2D )\n",
      "85/126: Analysing op name: block3_conv1/BiasAdd ( type:  BiasAdd )\n",
      "86/126: Analysing op name: block3_conv1/Relu ( type:  Relu )\n",
      "87/126: Analysing op name: block3_conv2/Conv2D ( type:  Conv2D )\n",
      "88/126: Analysing op name: block3_conv2/BiasAdd ( type:  BiasAdd )\n",
      "89/126: Analysing op name: block3_conv2/Relu ( type:  Relu )\n",
      "90/126: Analysing op name: block3_conv3/Conv2D ( type:  Conv2D )\n",
      "91/126: Analysing op name: block3_conv3/BiasAdd ( type:  BiasAdd )\n",
      "92/126: Analysing op name: block3_conv3/Relu ( type:  Relu )\n",
      "93/126: Analysing op name: block3_pool/MaxPool ( type:  MaxPool )\n",
      "94/126: Analysing op name: block4_conv1/Conv2D ( type:  Conv2D )\n",
      "95/126: Analysing op name: block4_conv1/BiasAdd ( type:  BiasAdd )\n",
      "96/126: Analysing op name: block4_conv1/Relu ( type:  Relu )\n",
      "97/126: Analysing op name: block4_conv2/Conv2D ( type:  Conv2D )\n",
      "98/126: Analysing op name: block4_conv2/BiasAdd ( type:  BiasAdd )\n",
      "99/126: Analysing op name: block4_conv2/Relu ( type:  Relu )\n",
      "100/126: Analysing op name: block4_conv3/Conv2D ( type:  Conv2D )\n",
      "101/126: Analysing op name: block4_conv3/BiasAdd ( type:  BiasAdd )\n",
      "102/126: Analysing op name: block4_conv3/Relu ( type:  Relu )\n",
      "103/126: Analysing op name: block4_pool/MaxPool ( type:  MaxPool )\n",
      "104/126: Analysing op name: block5_conv1/Conv2D ( type:  Conv2D )\n",
      "105/126: Analysing op name: block5_conv1/BiasAdd ( type:  BiasAdd )\n",
      "106/126: Analysing op name: block5_conv1/Relu ( type:  Relu )\n",
      "107/126: Analysing op name: block5_conv2/Conv2D ( type:  Conv2D )\n",
      "108/126: Analysing op name: block5_conv2/BiasAdd ( type:  BiasAdd )\n",
      "109/126: Analysing op name: block5_conv2/Relu ( type:  Relu )\n",
      "110/126: Analysing op name: block5_conv3/Conv2D ( type:  Conv2D )\n",
      "111/126: Analysing op name: block5_conv3/BiasAdd ( type:  BiasAdd )\n",
      "112/126: Analysing op name: block5_conv3/Relu ( type:  Relu )\n",
      "113/126: Analysing op name: block5_pool/MaxPool ( type:  MaxPool )\n",
      "114/126: Analysing op name: flatten/Shape ( type:  Shape )\n",
      "115/126: Analysing op name: flatten/strided_slice ( type:  StridedSlice )\n",
      "116/126: Analysing op name: flatten/Reshape/shape ( type:  Pack )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/126: Analysing op name: flatten/Reshape ( type:  Reshape )\n",
      "118/126: Analysing op name: fc1/MatMul ( type:  MatMul )\n",
      "119/126: Analysing op name: fc1/BiasAdd ( type:  BiasAdd )\n",
      "120/126: Analysing op name: fc1/Relu ( type:  Relu )\n",
      "121/126: Analysing op name: fc2/MatMul ( type:  MatMul )\n",
      "122/126: Analysing op name: fc2/BiasAdd ( type:  BiasAdd )\n",
      "123/126: Analysing op name: fc2/Relu ( type:  Relu )\n",
      "124/126: Analysing op name: predictions/MatMul ( type:  MatMul )\n",
      "125/126: Analysing op name: predictions/BiasAdd ( type:  BiasAdd )\n",
      "126/126: Analysing op name: predictions/Softmax ( type:  Softmax )\n",
      "Translation to CoreML spec completed. Now compiling and saving the CoreML model.\n",
      "\n",
      " Core ML model generated. Saved at location: models/vgg16.mlmodel \n",
      "\n",
      "Core ML input(s): \n",
      " [name: \"input_2__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 3\n",
      "    shape: 224\n",
      "    shape: 224\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      "]\n",
      "Core ML output(s): \n",
      " [name: \"predictions__Softmax__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 1000\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "coreml_model = tf_converter.convert(tf_model_path=str(MODELS/f'{arch_name}.pb'),\n",
    "                         mlmodel_path=MODELS/f'{arch_name}.mlmodel',\n",
    "                         input_name_shape_dict={\"prefix/\"+keras_model.input.name:(1,224,224,3)},\n",
    "                         output_feature_names=[keras_model.output.name],\n",
    "                         add_custom_layers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Keras and CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoreML to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ONNX model\n",
    "onnx_model = onnxmltools.convert_coreml(coreml_model, str(MODELS/f'{arch_name}.mlmodel'))\n",
    "# onnxmltools.utils.save_text(onnx_model, MODELS/f'{arch_name}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnxmltools.utils.save_model(onnx_model,  str(MODELS/f'{arch_name}.onnx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Keras and ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF to TFlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553436732"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_frozen_graph(str(MODELS/f'{arch_name}.pb'),\n",
    "                                                      keras_model.input.name.split(\":\")[:1],\n",
    "                                                      keras_model.output.name.split(\":\")[:1])\n",
    "tflite_model = converter.convert()\n",
    "open(MODELS/f\"{arch_name}.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('models/vgg16.onnx'),\n",
       " PosixPath('models/vgg16.tflite'),\n",
       " PosixPath('models/vgg16.mlmodel'),\n",
       " PosixPath('models/vgg16.pb'),\n",
       " PosixPath('models/vgg16.h5')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODELS.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Keras and TFlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=str(MODELS/f\"{arch_name}.tflite\"))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'name': 'input_2',\n",
       "   'index': 50,\n",
       "   'shape': array([  1, 224, 224,   3], dtype=int32),\n",
       "   'dtype': numpy.float32,\n",
       "   'quantization': (0.0, 0)}],\n",
       " [{'name': 'predictions/Softmax',\n",
       "   'index': 53,\n",
       "   'shape': array([   1, 1000], dtype=int32),\n",
       "   'dtype': numpy.float32,\n",
       "   'quantization': (0.0, 0)}])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_details, output_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = numpy_input\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "tflite_output = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.263924e-06, 4.362771e-05, 2.551505e-06, 2.809446e-06, ..., 8.950497e-06, 2.359440e-05, 2.745928e-04,\n",
       "        4.154908e-04]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras with TF\n",
    "if not inputs_same(keras_output[0], tflite_output[0]):\n",
    "    raise Exception(\"Keras and TFLite outputs are not same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "- There is a problem during batchnorm conversion - https://www.bountysource.com/issues/36614355-unable-to-import-frozen-graph-with-batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
