{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(10, 3, 224, 224, device='cuda')\n",
    "torch_model = torchvision.models.alexnet(pretrained=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%actual_input_1 : Float(10, 3, 224, 224)\n",
      "      %learned_0 : Float(64, 3, 11, 11)\n",
      "      %learned_1 : Float(64)\n",
      "      %learned_2 : Float(192, 64, 5, 5)\n",
      "      %learned_3 : Float(192)\n",
      "      %learned_4 : Float(384, 192, 3, 3)\n",
      "      %learned_5 : Float(384)\n",
      "      %learned_6 : Float(256, 384, 3, 3)\n",
      "      %learned_7 : Float(256)\n",
      "      %learned_8 : Float(256, 256, 3, 3)\n",
      "      %learned_9 : Float(256)\n",
      "      %learned_10 : Float(4096, 9216)\n",
      "      %learned_11 : Float(4096)\n",
      "      %learned_12 : Float(4096, 4096)\n",
      "      %learned_13 : Float(4096)\n",
      "      %learned_14 : Float(1000, 4096)\n",
      "      %learned_15 : Float(1000)) {\n",
      "  %17 : Float(10, 64, 55, 55) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[11, 11], pads=[2, 2, 2, 2], strides=[4, 4]](%actual_input_1, %learned_0, %learned_1), scope: AlexNet/Sequential[features]/Conv2d[0]\n",
      "  %18 : Float(10, 64, 55, 55) = onnx::Relu(%17), scope: AlexNet/Sequential[features]/ReLU[1]\n",
      "  %19 : Float(10, 64, 27, 27) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%18), scope: AlexNet/Sequential[features]/MaxPool2d[2]\n",
      "  %20 : Float(10, 192, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%19, %learned_2, %learned_3), scope: AlexNet/Sequential[features]/Conv2d[3]\n",
      "  %21 : Float(10, 192, 27, 27) = onnx::Relu(%20), scope: AlexNet/Sequential[features]/ReLU[4]\n",
      "  %22 : Float(10, 192, 13, 13) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%21), scope: AlexNet/Sequential[features]/MaxPool2d[5]\n",
      "  %23 : Float(10, 384, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%22, %learned_4, %learned_5), scope: AlexNet/Sequential[features]/Conv2d[6]\n",
      "  %24 : Float(10, 384, 13, 13) = onnx::Relu(%23), scope: AlexNet/Sequential[features]/ReLU[7]\n",
      "  %25 : Float(10, 256, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%24, %learned_6, %learned_7), scope: AlexNet/Sequential[features]/Conv2d[8]\n",
      "  %26 : Float(10, 256, 13, 13) = onnx::Relu(%25), scope: AlexNet/Sequential[features]/ReLU[9]\n",
      "  %27 : Float(10, 256, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%26, %learned_8, %learned_9), scope: AlexNet/Sequential[features]/Conv2d[10]\n",
      "  %28 : Float(10, 256, 13, 13) = onnx::Relu(%27), scope: AlexNet/Sequential[features]/ReLU[11]\n",
      "  %29 : Float(10, 256, 6, 6) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%28), scope: AlexNet/Sequential[features]/MaxPool2d[12]\n",
      "  %30 : Long() = onnx::Constant[value={0}](), scope: AlexNet\n",
      "  %31 : Tensor = onnx::Shape(%29), scope: AlexNet\n",
      "  %32 : Long() = onnx::Gather[axis=0](%31, %30), scope: AlexNet\n",
      "  %33 : Long() = onnx::Constant[value={9216}](), scope: AlexNet\n",
      "  %34 : Tensor = onnx::Unsqueeze[axes=[0]](%32)\n",
      "  %35 : Tensor = onnx::Unsqueeze[axes=[0]](%33)\n",
      "  %36 : Tensor = onnx::Concat[axis=0](%34, %35)\n",
      "  %37 : Float(10, 9216) = onnx::Reshape(%29, %36), scope: AlexNet\n",
      "  %38 : Float(10, 9216), %39 : Tensor = onnx::Dropout[ratio=0.5](%37), scope: AlexNet/Sequential[classifier]/Dropout[0]\n",
      "  %40 : Float(10, 4096) = onnx::Gemm[alpha=1, beta=1, transB=1](%38, %learned_10, %learned_11), scope: AlexNet/Sequential[classifier]/Dropout[0]\n",
      "  %41 : Float(10, 4096) = onnx::Relu(%40), scope: AlexNet/Sequential[classifier]/ReLU[2]\n",
      "  %42 : Float(10, 4096), %43 : Tensor = onnx::Dropout[ratio=0.5](%41), scope: AlexNet/Sequential[classifier]/Dropout[3]\n",
      "  %44 : Float(10, 4096) = onnx::Gemm[alpha=1, beta=1, transB=1](%42, %learned_12, %learned_13), scope: AlexNet/Sequential[classifier]/Dropout[3]\n",
      "  %45 : Float(10, 4096) = onnx::Relu(%44), scope: AlexNet/Sequential[classifier]/ReLU[5]\n",
      "  %output1 : Float(10, 1000) = onnx::Gemm[alpha=1, beta=1, transB=1](%45, %learned_14, %learned_15), scope: AlexNet/Sequential[classifier]/ReLU[5]\n",
      "  return (%output1);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(16) ]\n",
    "output_names = [ \"output1\" ]\n",
    "\n",
    "torch_out = torch.onnx._export(torch_model, dummy_input, \"alexnet.onnx\", verbose=True, input_names=input_names, output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2694, -1.4682, -1.4477,  ..., -1.4013, -1.1519,  1.3629],\n",
       "        [ 0.0960, -1.4116, -1.3971,  ..., -1.0261, -1.0680,  1.1595],\n",
       "        [-0.0173, -1.3886, -1.2807,  ..., -1.1756, -1.1435,  1.0807],\n",
       "        ...,\n",
       "        [ 0.1755, -1.4784, -1.2024,  ..., -1.1207, -1.0591,  1.4796],\n",
       "        [ 0.1555, -1.6090, -1.2815,  ..., -0.9031, -1.1223,  1.5993],\n",
       "        [ 0.2649, -0.9999, -1.3977,  ..., -1.2150, -0.8930,  0.9923]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with Onnx Model in Caffe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"./pytorch/alexnet.onnx\")\n",
    "\n",
    "# Check that the IR is well formed\n",
    "onnx.checker.check_model(model)\n",
    "\n",
    "# Print a human readable representation of the graph\n",
    "# print(onnx.helper.printable_graph(model.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caffe dependencies\n",
    "# !pip install -r https://raw.githubusercontent.com/pytorch/pytorch/master/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import caffe2.python.onnx.backend as backend\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA operators do not support 64-bit doubles, please use arr.astype(np.float32) or np.int32 for ints. Blob: actual_input_1 type: float64\n"
     ]
    }
   ],
   "source": [
    "rep = backend.prepare(model, device=\"CUDA:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs = rep.run(dummy_input.cpu().numpy().astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.26941356, -1.4682022 , -1.4477373 , ..., -1.4012641 ,\n",
       "        -1.1518751 ,  1.3629025 ],\n",
       "       [ 0.0959611 , -1.4116307 , -1.397087  , ..., -1.026058  ,\n",
       "        -1.0679855 ,  1.1594914 ],\n",
       "       [-0.01731079, -1.3886348 , -1.2806541 , ..., -1.1756328 ,\n",
       "        -1.1434869 ,  1.0807338 ],\n",
       "       ...,\n",
       "       [ 0.17552656, -1.4783663 , -1.2023933 , ..., -1.1206607 ,\n",
       "        -1.0591127 ,  1.4795922 ],\n",
       "       [ 0.15547907, -1.6090451 , -1.2814711 , ..., -0.90313953,\n",
       "        -1.1223465 ,  1.5992917 ],\n",
       "       [ 0.2648559 , -0.9998633 , -1.3977414 , ..., -1.2149727 ,\n",
       "        -0.8930128 ,  0.99228346]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the numerical correctness upto 3 decimal places\n",
    "np.testing.assert_almost_equal(torch_out.data.cpu().numpy(), outputs.output1, decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The ONNX exporter is a trace-based exporter, which means that it operates by executing your model once, and exporting the operators which were actually run during this run. This means that if your model is dynamic, e.g., changes behavior depending on input data, the export wonâ€™t be accurate. Similarly, a trace is likely to be valid only for a specific input size (which is one reason why we require explicit inputs on tracing.) We recommend examining the model trace and making sure the traced operators look reasonable.\n",
    "\n",
    "\n",
    "- PyTorch and Caffe2 often have implementations of operators with some numeric differences. Depending on model structure, these differences may be negligible, but they can also cause major divergences in behavior (especially on untrained models.) In a future release, we plan to allow Caffe2 to call directly to Torch implementations of operators, to help you smooth over these differences when precision is important, and to also document these differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
